
batch_size: 32
epochs: 100


vocab_size: 52000
hidden_size: 768
num_hidden_layers: 6
num_attention_heads: 12
max_position_embeddings: 515



